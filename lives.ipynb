{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attributedataset.datasetutils import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yml = 'configs/pascal_config.yml'\n",
    "with open(yml, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, num_classes = get_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2048, 14, 14])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeLossMatters(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 backbone='resnet50',\n",
    "                 freeze_backbone=False,\n",
    "                 use_feature=False,\n",
    "                 mod_schemes='LL-R',\n",
    "                 delta_rel=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      self.num_classes = num_classes\n",
    "      self.mod_schemes = mod_schemes\n",
    "      self.delta_rel = delta_rel / 100\n",
    "      self.use_feature = use_feature\n",
    "      self.clean_rate = 1.0\n",
    "\n",
    "      if use_feature:\n",
    "        self.backbone = None\n",
    "      elif backbone == 'resnet50':\n",
    "        self.backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2]) # (N, 2048, 7, 7)\n",
    "      else:\n",
    "        raise NotImplementedError\n",
    "      \n",
    "      if not use_feature:\n",
    "        if freeze_backbone:\n",
    "          for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "          for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "      \n",
    "      self.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "      if self.backbone is not None:\n",
    "        features = self.backbone(x) # (N, 2048, 7, 7)\n",
    "      else:\n",
    "        features = x\n",
    "\n",
    "      print(features.shape, type(features), features.dtype)\n",
    "\n",
    "      # adaptive global average pooling\n",
    "      features = F.adaptive_avg_pool2d(features, (1)).squeeze(-1).squeeze(-1) # (N, 2048, 1, 1)\n",
    "      \n",
    "      logits = self.fc(features) # (N, num_classes)\n",
    "      return logits\n",
    "    \n",
    "    def loss(self, x, labels):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        x: (N, num_classes)\n",
    "        labels: (N, num_classes) \n",
    "      \"\"\"\n",
    "      preds = self.forward(x)\n",
    "\n",
    "      batch_size = int(labels.shape[0])\n",
    "      num_classes = int(labels.shape[1])\n",
    "\n",
    "      loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "      loss_matrix = loss_fn(preds, labels) # (N, num_classes)\n",
    "      corrected_loss_matrix = loss_fn(preds, torch.logical_not(labels).float()) # (N, num_classes)\n",
    "      correction_idx = None\n",
    "\n",
    "      if self.clean_rate == 1.0:\n",
    "        return loss_matrix.mean(), correction_idx\n",
    "\n",
    "      if self.mod_schemes == 'LL-R':\n",
    "        k = math.ceil(batch_size * num_classes * (1-self.clean_rate))\n",
    "      elif self.mod_schemes == 'LL-Ct':\n",
    "        k = math.ceil(batch_size * num_classes * (1-self.clean_rate))\n",
    "      elif self.mod_schemes == 'LL-Cp':\n",
    "        k = math.ceil(batch_size * num_classes * self.delta_rel)\n",
    "      else:\n",
    "        raise NotImplementedError\n",
    "      \n",
    "      unobserved_loss = (labels == 0).bool() * loss_matrix # (N)\n",
    "      try:\n",
    "        topk = torch.topk(unobserved_loss.flatten(), k)\n",
    "      except:\n",
    "        print(batch_size)\n",
    "        print(num_classes)\n",
    "        print(k)\n",
    "        raise NotImplementedError('topk error')\n",
    "      topk_lossval = topk.values[-1]\n",
    "      correction_idx = torch.where(unobserved_loss > topk_lossval)\n",
    "\n",
    "      if self.mod_schemes == 'LL-R':\n",
    "        corrected_loss_matrix = torch.zeros_like(loss_matrix)\n",
    "\n",
    "      loss_matrix = torch.where(unobserved_loss < topk_lossval, loss_matrix, corrected_loss_matrix)\n",
    "\n",
    "      return loss_matrix.mean(), correction_idx\n",
    "    \n",
    "    def get_cam(self, x):\n",
    "      features = self.backbone(x) # (N, 2048, 7, 7)\n",
    "      CAM = F.conv2d(features, self.fc.weight.unsqueeze(-1).unsqueeze(-1)) # (N, num_classes, 1, 1)\n",
    "      return CAM\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "      for param in self.backbone.parameters():\n",
    "          param.requires_grad = True\n",
    "\n",
    "    def forward_linear(self, x):\n",
    "      x = self.fc(x)\n",
    "      return x\n",
    "    \n",
    "    def decrease_clean_rate(self):\n",
    "      self.clean_rate = self.clean_rate - self.delta_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LargeLossMatters(num_classes, backbone='resnet50', freeze_backbone=False, use_feature=False, mod_schemes='LL-R', delta_rel=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2048, 14, 14]) <class 'torch.Tensor'> torch.float32\n"
     ]
    }
   ],
   "source": [
    "X, y = batch\n",
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
